{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_lms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/lverwimp/RNN_language_modeling/blob/master/rnn_lms_extended.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "esuUK2ev_Nyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ]
    },
    {
      "metadata": {
        "id": "_yKJ-Plo_HTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib, collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UScGV-tTaZba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some global variables:"
      ]
    },
    {
      "metadata": {
        "id": "KNbwMREbacvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 20\n",
        "NUM_STEPS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hmCKPx4KEcG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading the data"
      ]
    },
    {
      "metadata": {
        "id": "-oKtBwJQAJED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get training, validation and test data:"
      ]
    },
    {
      "metadata": {
        "id": "t6AIeiR2BaMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/train.txt'\n",
        "valid_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/valid.txt'\n",
        "test_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/test.txt'\n",
        "train_file = urllib.urlopen(train_url).read()\n",
        "valid_file = urllib.urlopen(valid_url).read()\n",
        "test_file = urllib.urlopen(test_url).read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Ye3oJavH-8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The data looks like this:"
      ]
    },
    {
      "metadata": {
        "id": "GXEcoaWKIAtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "25354e27-c157-41db-9603-80d8e2740491"
      },
      "cell_type": "code",
      "source": [
        "print('{0}...'.format(valid_file[:500]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " consumers may want to move their telephones a little closer to the tv set \n",
            " <unk> <unk> watching abc 's monday night football can now vote during <unk> for the greatest play in N years from among four or five <unk> <unk> \n",
            " two weeks ago viewers of several nbc <unk> consumer segments started calling a N number for advice on various <unk> issues \n",
            " and the new syndicated reality show hard copy records viewers ' opinions for possible airing on the next day 's show \n",
            " interactive telephone technology...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ZF1PoUJDRkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<unk\\> is a symbol for the unknown words class, 'N' is a symbol used for the numbers class.\n",
        "  \n",
        "Convert data to correct format:"
      ]
    },
    {
      "metadata": {
        "id": "Y531EV5aDVd0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the string to a list and replace newlines with the end-of-sentence symbol\n",
        "train_text = [w for w in train_file.replace('\\n',' <eos>').split(' ')]\n",
        "valid_text = [w for w in valid_file.replace('\\n',' <eos>').split(' ')]\n",
        "test_text = [w for w in test_file.replace('\\n',' <eos>').split(' ')]\n",
        "\n",
        "# count the frequencies of the words in the training data\n",
        "counter = collections.Counter(train_text)\n",
        "\n",
        "# sort according to decreasing frequency\n",
        "count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "# words = list of all the words (in decreasing frequency)\n",
        "items, _ = list(zip(*count_pairs))\n",
        "\n",
        "# make a dictionary with a mapping from each word to an id; word with highest frequency gets lowest id etc.\n",
        "item_to_id = dict(zip(items, range(len(items))))\n",
        "id_to_item = dict(zip(range(len(items)), items))\n",
        "vocab_size = len(item_to_id)\n",
        "\n",
        "# convert the words to indices\n",
        "train_ids_large = [item_to_id[item] for item in train_text]\n",
        "valid_ids_large = [item_to_id[item] for item in valid_text]\n",
        "test_ids_large = [item_to_id[item] for item in test_text]\n",
        "\n",
        "# take a smaller subset to speed up training\n",
        "train_ids = train_ids_large[:200000]\n",
        "valid_ids = valid_ids_large[:20000]\n",
        "test_ids = test_ids_large[:20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6KQShlZFcGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once the data is converted to ids, it looks like this:"
      ]
    },
    {
      "metadata": {
        "id": "Vlo5SpAHFhLq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e23be379-d350-4dd0-ac93-f11a88a1805d"
      },
      "cell_type": "code",
      "source": [
        "print(valid_ids[:100])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 1133, 94, 359, 6, 330, 52, 9837, 7, 327, 2477, 6, 0, 663, 389, 2, 3, 1, 1, 2975, 2159, 10, 382, 1069, 2348, 90, 100, 848, 199, 1, 12, 0, 3384, 1120, 8, 4, 73, 21, 212, 347, 37, 259, 1, 1, 2, 3, 76, 423, 196, 3918, 5, 250, 1796, 1, 581, 3529, 893, 2375, 7, 4, 298, 12, 2710, 17, 1187, 1, 251, 2, 3, 9, 0, 36, 9923, 3748, 465, 711, 2999, 2038, 3918, 135, 6146, 12, 495, 5895, 17, 0, 131, 273, 10, 465, 2, 3, 9959, 733, 504, 31, 642, 7, 36, 6499]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FIhqMJ2CKMxP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code for building, training and testing neural language models"
      ]
    },
    {
      "metadata": {
        "id": "jBnJVfPuNzmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Class for the language model:"
      ]
    },
    {
      "metadata": {
        "id": "e_IlLSYXN1h7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class rnn_lm(object):\n",
        "  '''\n",
        "  This is a class to build and execute a recurrent neural network language model.\n",
        "  '''\n",
        "  \n",
        "  def __init__(self,\n",
        "              cell='LSTM',\n",
        "              optimizer='SGD',\n",
        "              lr=1,\n",
        "              vocab_size=10000,\n",
        "              embedding_size=64,\n",
        "              hidden_size=128,\n",
        "              dropout_rate=0.5,\n",
        "              is_training=True):\n",
        "    # hyperparameters that can be changed\n",
        "    self.which_cell = cell\n",
        "    self.which_optimizer = optimizer\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.is_training = is_training\n",
        "    self.lr = lr\n",
        "    \n",
        "    # hard-coded hyperparameters\n",
        "    self.batch_size = BATCH_SIZE\n",
        "    self.num_steps = NUM_STEPS\n",
        "    self.max_grad_norm = 5\n",
        "    \n",
        "    \n",
        "    self.init_graph()\n",
        "    \n",
        "    self.output, self.state = self.feed_to_network()\n",
        "    \n",
        "    self.loss = self.calc_loss(self.output)\n",
        "    \n",
        "    if self.is_training:\n",
        "      self.update_params(self.loss)\n",
        "    \n",
        "    \n",
        "  def init_graph(self):\n",
        "    '''\n",
        "    This function initializes all elements of the network.\n",
        "    '''\n",
        "    \n",
        "    self.inputs = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, self.num_steps])\n",
        "    self.targets = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, self.num_steps])\n",
        "    \n",
        "    # input embedding weights\n",
        "    self.embedding = tf.get_variable(\"embedding\", \n",
        "                                     [self.vocab_size, self.embedding_size], \n",
        "                                     dtype=tf.float32)\n",
        "    \n",
        "    # hidden layer\n",
        "    if self.which_cell == 'LSTM':\n",
        "      self.basic_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size)\n",
        "    elif self.which_cell == 'RNN':\n",
        "      self.basic_cell = tf.contrib.rnn.BasicRNNCell(self.hidden_size)\n",
        "    else:\n",
        "      raise ValueError(\"Specify which type of RNN you want to use: RNN or LSTM.\")\n",
        "      \n",
        "    # apply dropout  \n",
        "    self.cell = tf.contrib.rnn.DropoutWrapper(self.basic_cell, \n",
        "                                              output_keep_prob=self.dropout_rate)\n",
        "    \n",
        "    # initial state contains all zeros\n",
        "    self.initial_state = self.cell.zero_state(self.batch_size, tf.float32)\n",
        "    \n",
        "    # output weight matrix and bias\n",
        "    self.softmax_w = tf.get_variable(\"softmax_w\",\n",
        "                                     [self.hidden_size, self.vocab_size], \n",
        "                                     dtype=tf.float32)\n",
        "    self.softmax_b = tf.get_variable(\"softmax_b\",\n",
        "                                     [self.vocab_size], \n",
        "                                     dtype=tf.float32)\n",
        "    \n",
        "    self.initial_state = self.cell.zero_state(self.batch_size, dtype=tf.float32)\n",
        "    \n",
        "    \n",
        "  def feed_to_network(self):\n",
        "    '''\n",
        "    This function feeds the input to the network and returns the output and the state.\n",
        "   \n",
        "    '''\n",
        "    \n",
        "    # map input indices to continuous input vectors\n",
        "    inputs = tf.nn.embedding_lookup(self.embedding, self.inputs)\n",
        "\n",
        "\t  # use dropout on the input embeddings\n",
        "    inputs = tf.nn.dropout(inputs, self.dropout_rate)\n",
        "    \n",
        "    state = self.initial_state\n",
        "    \n",
        "    # feed inputs to network: outputs = predictions, state = new hidden state\n",
        "    outputs, state = tf.nn.dynamic_rnn(self.cell, inputs, sequence_length=None, initial_state=state)\n",
        "    \n",
        "    output = tf.reshape(tf.concat(outputs, 1), [-1, self.hidden_size])\n",
        "    \n",
        "    return output, state\n",
        "    \n",
        "  \n",
        "  def calc_loss(self, output):\n",
        "    \n",
        "    # calculate logits\n",
        "    # shape of logits = [batch_size*num_steps, vocab_size]\n",
        "    logits = tf.matmul(output, self.softmax_w) + self.softmax_b\n",
        "      \n",
        "    # calculate cross entropy loss\n",
        "    # reshape targets such that it has shape [batch_size*num_steps]\n",
        "    # loss: contains loss for every time step in every batch\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=tf.reshape(self.targets, [-1]), logits=logits)\n",
        "      \n",
        "    # average loss per batch\n",
        "    avg_loss = tf.reduce_sum(loss) / self.batch_size\n",
        "    \n",
        "    return avg_loss\n",
        "  \n",
        "  def update_params(self, loss):\n",
        "    \n",
        "    # calculate gradients for all trainable variables \n",
        "    # + clip them if their global norm > 5 (prevents exploding gradients)\n",
        "    grads, _ = tf.clip_by_global_norm(\n",
        "        tf.gradients(loss, tf.trainable_variables()), self.max_grad_norm)\n",
        "    \n",
        "    if self.which_optimizer == 'SGD':\n",
        "      optimizer = tf.train.GradientDescentOptimizer(self.lr)\n",
        "    elif self.which_optimizer == 'Adam':\n",
        "      optimizer = tf.train.AdamOptimizer(self.lr)\n",
        "    else:\n",
        "      raise ValueError(\"Specify which type of optimizer you want to use: SGD or Adam.\")\n",
        "    \n",
        "    # update the weights\n",
        "    self.train_op = optimizer.apply_gradients(\n",
        "\t\t\t\tzip(grads, tf.trainable_variables()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIHeGqTCW8J-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a class that will generate mini-batches from the data."
      ]
    },
    {
      "metadata": {
        "id": "sEvlMOEJa4qU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class batchGenerator(object):\n",
        "  '''\n",
        "  This class generates batches for a dataset.\n",
        "  Input argument:\n",
        "    data: list of indices (word ids)\n",
        "  '''\n",
        "  \n",
        "  def __init__(self, data):\n",
        "    '''\n",
        "    Prepares a dataset.\n",
        "    '''\n",
        "  \n",
        "    data_array = np.array(data)\n",
        "\n",
        "    len_batch_instance = len(data) / BATCH_SIZE\n",
        "\n",
        "    data_array = data_array[:BATCH_SIZE*len_batch_instance]\n",
        "\n",
        "    # divide data in BATCH_SIZE parts\n",
        "    self.data_reshaped = np.reshape(data_array, (BATCH_SIZE, len_batch_instance))\n",
        "\n",
        "    # number of mini-batches that can be generated\n",
        "    self.num_batches_in_data = len_batch_instance / NUM_STEPS - 1\n",
        "    \n",
        "    self.curr_idx = 0\n",
        "  \n",
        "  def generate(self):\n",
        "    '''\n",
        "    Generates\n",
        "      input_batch: numpy array or None, if the end of the dataset is reached\n",
        "      target_batch: numpy array or None, if the end of the dataset is reached\n",
        "      end_reached: boolean, True is end of dataset is reached\n",
        "    '''\n",
        "    \n",
        "    if self.curr_idx >= self.num_batches_in_data:\n",
        "      return None, None, True\n",
        "\n",
        "    # input: take slice of size BATCH_\n",
        "    input_batch = self.data_reshaped[:,self.curr_idx*BATCH_SIZE:self.curr_idx*BATCH_SIZE+BATCH_SIZE]\n",
        "    \n",
        "    # target = input shifted 1 time step\n",
        "    target_batch = self.data_reshaped[:,self.curr_idx*BATCH_SIZE+1:self.curr_idx*BATCH_SIZE+BATCH_SIZE+1]    \n",
        "\n",
        "    self.curr_idx += 1\n",
        "    \n",
        "    return input_batch, target_batch, False\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_SB0UTRdnU5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is an example of how batchGenerator can be used. You will notice that the target batch contains the same indices as the input batch, but shifted one (time) step to the right."
      ]
    },
    {
      "metadata": {
        "id": "qHiY_eJ0dpUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        },
        "outputId": "7d6c8deb-5652-4f68-db8b-8b6d07ab3ea6"
      },
      "cell_type": "code",
      "source": [
        "generator = batchGenerator(valid_ids)\n",
        "input_batch, target_batch, end_reached = generator.generate()\n",
        "print('This is what an input batch looks like:\\n{0}'.format(input_batch))\n",
        "print('And this is what a target batch looks like:\\n{0}'.format(target_batch))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is what an input batch looks like:\n",
            "[[   2 1133   94  359    6  330   52 9837    7  327 2477    6    0  663\n",
            "   389    2    3    1    1 2975]\n",
            " [  30   15   10 1540    6   26   44    4    4  626 2039    1  173    2\n",
            "     3   65   47  584    6  189]\n",
            " [   1   95 2469   11  390    1   47  214 9936   20    1   80   26 1950\n",
            "    67    0    1    5    1  175]\n",
            " [ 146 2370   16    2    3  640  748 3382 4740 2785   57  336  562    8\n",
            "  1120   23    7   13    4   49]\n",
            " [  47 3280   11   24 2785   37   55    5    0   62 1379 1557  280    1\n",
            "    23    0  948    8 6393   37]\n",
            " [  15  176   33 1056    6  330  122 1296   28    1 1853    8  133 8666\n",
            "  9744    2    3   68   24 2670]\n",
            " [1094  485    1 3218   94   26  659    6  621   11 1030   30 1371   37\n",
            "  6552 8336  128   20   39    1]\n",
            " [   2    3   36  632 4168   83 3089   96 3254 2369    0  695  904   12\n",
            "    28  463    5 1768    1    1]\n",
            " [ 607  363    2    3    1 2848   10    1 3404  193    7 5443    2    3\n",
            "   190    1   35    6   26   75]\n",
            " [   6  300   30    0 2035 1205   17    0  911 7360  160  128 1155   15\n",
            "     2    3  111  379 2932   51]\n",
            " [3059   70   41   68  229    1   47  214 6300    2    3 1090  167   11\n",
            "   846 9920   53 2932   10 7448]\n",
            " [1558 6121   37 5187 7705   35 1899  361    9    0   36  839   27 8690\n",
            "   946   57  160  162    8    0]\n",
            " [ 442   23 9976    2    3   12 1224   29  595    7   13    4   22  502\n",
            "    21    0 3414 3397   19    7]\n",
            " [1390 9896    9  681    0  599 2272  680   19    0 1860    2    3   17\n",
            "  9758   29  490    7  242  116]\n",
            " [ 288  489   31    4   22  247   72  547    2    3    1  720   51   16\n",
            "    15  955    6 3751   72   30]\n",
            " [5319   48    2    3    0   61   48 8597   33  325    6   88  122    5\n",
            "   997   12    7  121   45  401]\n",
            " [ 242  208   37  891  137   80  379   52   72  461  290   46   56    4\n",
            "     4    2    3    0 2763   17]\n",
            " [   8  271   21 2165    1  645    2    3    0  213    8    7    4 1230\n",
            "  5857   85    7 3167  389   18]\n",
            " [   9  289  474    2    3   24    1   25  233   71    9  277  353  572\n",
            "     5    1 3050    1   81    7]\n",
            " [1836 6986    4   73  394   71    9  152  155  291    5 5411  931    5\n",
            "   541   81   25 1235    7  277]]\n",
            "And this is what a target batch looks like:\n",
            "[[1133   94  359    6  330   52 9837    7  327 2477    6    0  663  389\n",
            "     2    3    1    1 2975 2159]\n",
            " [  15   10 1540    6   26   44    4    4  626 2039    1  173    2    3\n",
            "    65   47  584    6  189 1699]\n",
            " [  95 2469   11  390    1   47  214 9936   20    1   80   26 1950   67\n",
            "     0    1    5    1  175    1]\n",
            " [2370   16    2    3  640  748 3382 4740 2785   57  336  562    8 1120\n",
            "    23    7   13    4   49  258]\n",
            " [3280   11   24 2785   37   55    5    0   62 1379 1557  280    1   23\n",
            "     0  948    8 6393   37   11]\n",
            " [ 176   33 1056    6  330  122 1296   28    1 1853    8  133 8666 9744\n",
            "     2    3   68   24 2670 5987]\n",
            " [ 485    1 3218   94   26  659    6  621   11 1030   30 1371   37 6552\n",
            "  8336  128   20   39    1    8]\n",
            " [   3   36  632 4168   83 3089   96 3254 2369    0  695  904   12   28\n",
            "   463    5 1768    1    1    1]\n",
            " [ 363    2    3    1 2848   10    1 3404  193    7 5443    2    3  190\n",
            "     1   35    6   26   75    6]\n",
            " [ 300   30    0 2035 1205   17    0  911 7360  160  128 1155   15    2\n",
            "     3  111  379 2932   51   40]\n",
            " [  70   41   68  229    1   47  214 6300    2    3 1090  167   11  846\n",
            "  9920   53 2932   10 7448    2]\n",
            " [6121   37 5187 7705   35 1899  361    9    0   36  839   27 8690  946\n",
            "    57  160  162    8    0   61]\n",
            " [  23 9976    2    3   12 1224   29  595    7   13    4   22  502   21\n",
            "     0 3414 3397   19    7    1]\n",
            " [9896    9  681    0  599 2272  680   19    0 1860    2    3   17 9758\n",
            "    29  490    7  242  116   24]\n",
            " [ 489   31    4   22  247   72  547    2    3    1  720   51   16   15\n",
            "   955    6 3751   72   30  144]\n",
            " [  48    2    3    0   61   48 8597   33  325    6   88  122    5  997\n",
            "    12    7  121   45  401    1]\n",
            " [ 208   37  891  137   80  379   52   72  461  290   46   56    4    4\n",
            "     2    3    0 2763   17  331]\n",
            " [ 271   21 2165    1  645    2    3    0  213    8    7    4 1230 5857\n",
            "    85    7 3167  389   18    0]\n",
            " [ 289  474    2    3   24    1   25  233   71    9  277  353  572    5\n",
            "     1 3050    1   81    7 2113]\n",
            " [6986    4   73  394   71    9  152  155  291    5 5411  931    5  541\n",
            "    81   25 1235    7  277    5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vBbmu8MyeRjg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a function that does one pass over the whole dataset. If we are training the model, it will update the parameters and return the perplexity. Otherwise, it will just return the perplexity."
      ]
    },
    {
      "metadata": {
        "id": "u0QxAecTZIOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_epoch(session, rnn, data, is_training=True):\n",
        "    '''\n",
        "    This function runs a single epoch (pass) over the data,\n",
        "    updating the model parameters if we are training,\n",
        "    and returns the perplexity.\n",
        "    Input arguments:\n",
        "      rnn: object of the rnn_lm class\n",
        "      data: list of word indices\n",
        "      is_training: boolean, True is we are training the model\n",
        "    Returns:\n",
        "      ppl: float, perplexity of the dataset\n",
        "    '''\n",
        "  \n",
        "    generator = batchGenerator(data)\n",
        "      \n",
        "    state = session.run(rnn.initial_state)\n",
        "    sum_loss = 0.0\n",
        "    iters = 0\n",
        "      \n",
        "    while True:\n",
        "\n",
        "      input_batch, target_batch, end_reached = generator.generate()\n",
        "        \n",
        "      if end_reached:\n",
        "        break\n",
        "\n",
        "      feed_dict = {rnn.inputs: input_batch,\n",
        "                  rnn.targets: target_batch,\n",
        "                  rnn.initial_state : state}\n",
        "\n",
        "      fetches = {'loss': rnn.loss,\n",
        "                'state': rnn.state}\n",
        "      \n",
        "      if is_training:\n",
        "        fetches['train_op'] = rnn.train_op\n",
        "\n",
        "      result = session.run(fetches, feed_dict)\n",
        "        \n",
        "      state = result['state']\n",
        "      loss = result['loss']\n",
        "\n",
        "      sum_loss += loss\n",
        "      # the loss is an average over num_steps\n",
        "      iters += NUM_STEPS\n",
        "        \n",
        "    # calculate perplexity    \n",
        "    ppl = np.exp(sum_loss / iters)\n",
        "    \n",
        "    return ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CY4KxCsUenOy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This function can be called to build, train and test models with different parameter settings. "
      ]
    },
    {
      "metadata": {
        "id": "5K8dJkswaT7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_lm(cell='LSTM', optimizer='SGD', lr=1, \n",
        "           embedding_size=64, hidden_size=128, \n",
        "           dropout_rate=0.5, inspect_emb=False):\n",
        "  '''\n",
        "  Creates training, validation and/or test models,\n",
        "  trains, validates and/or tests the model.\n",
        "  '''\n",
        "  \n",
        "  with tf.Graph().as_default():\n",
        "\n",
        "      # create the models\n",
        "      with tf.variable_scope(\"Model\"):\n",
        "        rnn_train = rnn_lm(cell=cell,\n",
        "                           optimizer=optimizer, \n",
        "                           lr=lr,\n",
        "                           vocab_size=vocab_size,\n",
        "                           embedding_size=embedding_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "        \n",
        "        saver = tf.train.Saver()\n",
        "        \n",
        "      with tf.variable_scope(\"Model\", reuse=True):\n",
        "        rnn_valid = rnn_lm(cell=cell, \n",
        "                           optimizer=optimizer,\n",
        "                           lr=lr,\n",
        "                           vocab_size=vocab_size, \n",
        "                           embedding_size=embedding_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           dropout_rate=dropout_rate,\n",
        "                           is_training=False)\n",
        "        \n",
        "      with tf.variable_scope(\"Model\", reuse=True):\n",
        "        rnn_test = rnn_lm(cell=cell, \n",
        "                           optimizer=optimizer, \n",
        "                           lr=lr,\n",
        "                           vocab_size=vocab_size,\n",
        "                           embedding_size=embedding_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           dropout_rate=dropout_rate,\n",
        "                           is_training=False)\n",
        "      \n",
        "\n",
        "      sv = tf.train.Supervisor()\n",
        "\n",
        "      with sv.managed_session(config=tf.ConfigProto()) as session:\n",
        "        \n",
        "        for i in xrange(5):\n",
        "          \n",
        "          print('Epoch {0}'.format(i+1))\n",
        "\n",
        "          train_ppl = run_epoch(session, rnn_train, train_ids)\n",
        "          print('train_ppl: {0}'.format(train_ppl))\n",
        "\n",
        "          valid_ppl = run_epoch(session, rnn_valid, valid_ids, is_training=False)\n",
        "          print('valid_ppl: {0}'.format(valid_ppl))\n",
        "          \n",
        "        save_path = saver.save(session, \"models/rnn.ckpt\")\n",
        "        print('Saved the model to ',save_path)\n",
        "\n",
        "        test_ppl = run_epoch(session, rnn_test, test_ids, is_training=False)\n",
        "        print('test_ppl: {0}'.format(test_ppl))\n",
        "        \n",
        "      if inspect_emb: \n",
        "        emb_matrix = tf.get_default_graph().get_tensor_by_name(\"Model/embedding:0\")\n",
        "        \n",
        "        return emb_matrix\n",
        "      \n",
        "      else:\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    \n",
        "        \n",
        "        \n",
        "  \n",
        "        \n",
        "      \n",
        "      \n",
        "        \n",
        "     \n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbEp9tdFKXA4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training networks"
      ]
    },
    {
      "metadata": {
        "id": "a61RdtDCKhmp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training neural networks requires a lot of hyperparameter tuning. The hyperparameters of a neural network are for example the type of cell, its size, the method that is used for updating its parameters (also called 'optimizer' ), the type and strength of regularization, ... . All these hyperparameters have to be chosen before the network can built, trained and tested, and they all have to some extent an influence on the  performance of the model."
      ]
    },
    {
      "metadata": {
        "id": "j3bN2Mvmo_8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recurrent neural networks are neural networks that take as input a combination of the standard input and the hidden state of the previous time step. Let's first train a simple recurrent neural network (RNN) as a language model. The RNN, which is shown in the image below, computes a hidden state $\\mathbf{h}_t$ for timestep $t$ based on the current input word $\\mathbf{x}_t$, multiplied by its weight matrix $\\mathbf{W}$, the previous hidden state $\\mathbf{h}_{t-1}$, multiplied by its own weight matrix $\\mathbf{U}$, and a bias vector $\\mathbf{b}$. Usually, an RNN uses a $tanh$ as non-linear function. The result of the non-linearity is the new hidden state of the network, $\\mathbf{h}_t$, which is again transformed by a weight matrix and bias vector before a softmax non-linearity is applied. The output of the softmax contains values between 0 and 1, and the sum of all values sums to 1, so the output can be interpreted as a probability distribution. The final prediction of the network is then the largest value in $\\mathbf{y}_t$."
      ]
    },
    {
      "metadata": {
        "id": "nk3zeBTIdwuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![vanilla_RNN](https://github.com/lverwimp/RNN_language_modeling/blob/master/vanilla_RNN.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "yUR-tGjo7x-d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Often the input word vector $\\mathbf{x}_t$ is a one-hot vector, which means that the vector contains all zeros and a single one at the index of the current word. Multiplying $\\mathbf{x}_t$ with its weight matrix $\\mathbf{W}$ then boils down to a simple lookup. The result is a lower-dimensional, continuous word embedding $\\mathbf{e}_t$. If the language model is properly trained, certain semantic and syntactic properties will be encoded as vector offsets in the embedding space. A famous example is the vector offset for male - female, which is shown in the example below:"
      ]
    },
    {
      "metadata": {
        "id": "M3DDEbxR7aka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/lverwimp/RNN_language_modeling/blob/master/kingqueen.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "zI30kaseLmVT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "42u843fb9qq2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now train a simple RNN as language model."
      ]
    },
    {
      "metadata": {
        "id": "KRUa0rDYc7SC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "da37ad5f-526d-434e-b2e2-8f790ae15f76"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='RNN')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 28579.2624974\n",
            "valid_ppl: 7976.3365824\n",
            "Epoch 2\n",
            "train_ppl: 10458.1135736\n",
            "valid_ppl: 1364.88939657\n",
            "Epoch 3\n",
            "train_ppl: 1536.37432389\n",
            "valid_ppl: 2130.04265576\n",
            "Epoch 4\n",
            "train_ppl: 870.760132806\n",
            "valid_ppl: 709.111377606\n",
            "Epoch 5\n",
            "train_ppl: 713.030860672\n",
            "valid_ppl: 724.993998427\n",
            "test_ppl: 689.391726604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "osTYguHZprBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You see that both the training perplexity and the validation perplexity decreased during training, which is a good sign. However, notice that the validation perplexity of epoch 5 is slightly higher than the validation perplexity of epoch 4. \n"
      ]
    },
    {
      "metadata": {
        "id": "dWILisHi1xHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "22aad054-4419-4398-82b7-218e5dfd58df"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='RNN', optimizer='Adam')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 8.3480932363e+189\n",
            "valid_ppl: 8.94273109753e+240\n",
            "Epoch 2\n",
            "train_ppl: 8.90212615289e+269\n",
            "valid_ppl: 2.70133700595e+271\n",
            "Epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_ppl: inf\n",
            "valid_ppl: inf\n",
            "Epoch 4\n",
            "train_ppl: inf\n",
            "valid_ppl: inf\n",
            "Epoch 5\n",
            "train_ppl: inf\n",
            "valid_ppl: inf\n",
            "test_ppl: inf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8wKt7L9aPLfs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learning rate"
      ]
    },
    {
      "metadata": {
        "id": "EXDniSW54NfB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Judging from the perplexities above, it seems like the Adam optimizer is a bad choice for training our network! However, the interplay between the different hyperparameters of a neural network is complicated, and it is very well possible that a specific optimizer needs a different learning rate. \n",
        "Let's try a learning rate of 0.01 instead of 1:"
      ]
    },
    {
      "metadata": {
        "id": "pPl3KiSs5kQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "6c9b9d68-85c8-4af6-f42a-7658ff7e2b0d"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='RNN', optimizer='Adam', lr=0.01)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 1057.75617242\n",
            "valid_ppl: 958.832506035\n",
            "Epoch 2\n",
            "train_ppl: 564.324279113\n",
            "valid_ppl: 826.433342462\n",
            "Epoch 3\n",
            "train_ppl: 433.956799222\n",
            "valid_ppl: 793.489183177\n",
            "Epoch 4\n",
            "train_ppl: 364.952622399\n",
            "valid_ppl: 723.403317321\n",
            "Epoch 5\n",
            "train_ppl: 324.387741371\n",
            "valid_ppl: 699.624224383\n",
            "test_ppl: 532.177735851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gcNjIbzgDUuk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This time, the network is converging nicely. Maybe reducing the learning rate even further helps? Let's try a learning rate of 0.001:"
      ]
    },
    {
      "metadata": {
        "id": "UyUTwGvF7Iyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "bbccda5f-093f-497f-e27a-1db96cec8ba2"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='RNN', optimizer='Adam', lr=0.001)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 647.90650982\n",
            "valid_ppl: 490.249928851\n",
            "Epoch 2\n",
            "train_ppl: 378.543344185\n",
            "valid_ppl: 413.048300797\n",
            "Epoch 3\n",
            "train_ppl: 300.501997416\n",
            "valid_ppl: 375.886351108\n",
            "Epoch 4\n",
            "train_ppl: 258.467386044\n",
            "valid_ppl: 367.867747945\n",
            "Epoch 5\n",
            "train_ppl: 232.486608834\n",
            "valid_ppl: 356.596671902\n",
            "test_ppl: 286.110701589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nNkyWjQNCjja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see an additional improvement. Let's see what reducing the learning rate even further, to 0.0001, gives:"
      ]
    },
    {
      "metadata": {
        "id": "Zn3TWmSz-SyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5299fffd-6aec-4932-c3f2-22bce284dd0a"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='RNN', optimizer='Adam', lr=0.0001)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 1366.65057312\n",
            "valid_ppl: 677.639747264\n",
            "Epoch 2\n",
            "train_ppl: 630.575866312\n",
            "valid_ppl: 690.140848653\n",
            "Epoch 3\n",
            "train_ppl: 625.483174618\n",
            "valid_ppl: 707.694743583\n",
            "Epoch 4\n",
            "train_ppl: 620.683702468\n",
            "valid_ppl: 1629.80400103\n",
            "Epoch 5\n",
            "train_ppl: 668.006540818\n",
            "valid_ppl: 1913.05069198\n",
            "test_ppl: 1789.96267687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6FQejsJzC4TO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we see an interesting result: the training perplexity decreased between epoch 0 and 4, but the validation perplexity is continuously increasing. For epoch 5, even the training perplexity increased again. This is an example of a learning rate that is too small: the steps that the network is making are too small."
      ]
    },
    {
      "metadata": {
        "id": "FdVPv212Lem5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Type of RNN cell"
      ]
    },
    {
      "metadata": {
        "id": "2ZHyiycZCemZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A simple RNN has some disadvantages: it often suffers from the so-called *vanishing and exploding gradients* problem. Neural networks are trained with an algorithm called backpropagation, which computes the gradients of the loss with respect to all parameters in the network. For a language model, the loss of the network is called the *cross entropy*, and it is equal to the average negative log probability for every word in the data. The perplexity of the language model is simply the exponential of the cross entropy. In the case of the simple RNN shown above, the parameters would be the weight matrices $\\mathbf{W}$, $\\mathbf{U}$ and $\\mathbf{V}$ and the bias vectors $\\mathbf{b}$ and $\\mathbf{b_v}$. The gradients of the loss with respect to the parameters $\\mathbf{V}$ and $\\mathbf{b_v}$ can be calculated directly, but the gradients with respect to the other parameters in the network are calculated based on the chain rule, which results in multiplying many terms. Moreover, an RNN is typically *unrolled in time*, which means that you also want to update the weights for the words seen before. If the terms in the multiplication are very small or very  large, they can quickly get even smaller (vanish) or larger (explode). The exploding gradients problem can relatively easily be solved by clipping the (norm of) the gradients if they become too large, the vanishing gradients problem is (at least partially) solved by using another type of RNN cell, such as a long short-term memory (LSTM) cell."
      ]
    },
    {
      "metadata": {
        "id": "L-cN7Ox1_KTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "An LSTM contains two hidden states instead of one, a cell state $\\mathbf{c}_t$ and a hidden state $\\mathbf{h}_t$, and  three gates, the input gate, forget gate and output gate. The gates are shown in the upper part of the figure below: they have a sigmoid activation function, which makes sure that the output values are all between 0 and 1. The forget gate $\\mathbf{f}_t$ is combined with the cell state $\\mathbf{c}_t$: it thus decides which parts of the previous cell state should be forgetten (values close to 0) and which not (values close to 1). A new cell state is then calculated based on a combination of the input gate $\\mathbf{i}_t$, which decides what should be added, and the candidate values $\\mathbf{p}_t$, which are the result of a $tanh$ non-linearity. The new cell state $\\mathbf{c}_t$ is then put through another $tanh$, and combined with the output gate, which decides which part of the input should be let through to the new hidden state $\\mathbf{h}_t$. The last part of the network is the equal to the simple RNN. This [blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) gives a great description of how an LSTM cell works."
      ]
    },
    {
      "metadata": {
        "id": "LA-MvI3y-Yd0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/lverwimp/RNN_language_modeling/blob/master/LSTM.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "oQWpcWb9Hu6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We take the optimal combination of optimizer (Adam) and learning rate (0.001) for an RNN, and use it to train an LSTM:"
      ]
    },
    {
      "metadata": {
        "id": "IoKmC2JwCYhq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0e4e631b-ca0b-420b-dd07-9c7bb54535cb"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='LSTM', optimizer='Adam', lr=0.001)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 656.82063114\n",
            "valid_ppl: 529.864473663\n",
            "Epoch 2\n",
            "train_ppl: 424.844078727\n",
            "valid_ppl: 464.263171504\n",
            "Epoch 3\n",
            "train_ppl: 356.302922604\n",
            "valid_ppl: 419.632020537\n",
            "Epoch 4\n",
            "train_ppl: 312.305264384\n",
            "valid_ppl: 397.430353409\n",
            "Epoch 5\n",
            "train_ppl: 279.950894164\n",
            "valid_ppl: 376.370915052\n",
            "test_ppl: 308.514639823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AzvS-x9jIKm3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Surprise! The LSTM gives a worse test perplexity, 308.5, than the RNN with the same hyperparameters, 286.1. Looking at the evolution of the perplexities over epochs, we see that they only slowly decrease. Maybe we need a larger learning rate for an LSTM?"
      ]
    },
    {
      "metadata": {
        "id": "lkIJOt8jHoMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "79f9de2a-f817-44b7-c302-2141a72bb028"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='LSTM', optimizer='Adam', lr=0.01, inspect_emb=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 481.709334113\n",
            "valid_ppl: 396.625967937\n",
            "Epoch 2\n",
            "train_ppl: 286.597902762\n",
            "valid_ppl: 355.204807228\n",
            "Epoch 3\n",
            "train_ppl: 235.102307065\n",
            "valid_ppl: 341.794086337\n",
            "Epoch 4\n",
            "train_ppl: 207.242568642\n",
            "valid_ppl: 341.275447747\n",
            "Epoch 5\n",
            "train_ppl: 188.696659696\n",
            "valid_ppl: 349.23735006\n",
            "test_ppl: 264.915329849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-38546940d49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minspect_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-9679138f901c>\u001b[0m in \u001b[0;36mrun_lm\u001b[0;34m(cell, optimizer, lr, embedding_size, hidden_size, dropout_rate, inspect_emb)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minspect_emb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0minspect_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HSv59sc7JW6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This perplexity is already much better. By further optimizing of the learning rate and/or optimizer, we could probably get even lower perplexities."
      ]
    },
    {
      "metadata": {
        "id": "MGAY_hhfNLj5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Size of the embedding"
      ]
    },
    {
      "metadata": {
        "id": "jZ87PmaPJlib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now take a look at the influence of the size of the LSTM on its performance. By default, we train a model with embeddings of size 64 and a hidden layer of size 128. Let's see what happens if we reduce the size of the embedding:"
      ]
    },
    {
      "metadata": {
        "id": "q2d_Kx8zJGk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9ad75cc0-6d9a-4337-d957-fbc55eed3f4c"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='LSTM', optimizer='Adam', lr=0.01, embedding_size=16)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 519.359682418\n",
            "valid_ppl: 5124521.52183\n",
            "Epoch 2\n",
            "train_ppl: 325.127520433\n",
            "valid_ppl: 384.575596662\n",
            "Epoch 3\n",
            "train_ppl: 273.853564489\n",
            "valid_ppl: 366.642785843\n",
            "Epoch 4\n",
            "train_ppl: 245.163913857\n",
            "valid_ppl: 358.26870915\n",
            "Epoch 5\n",
            "train_ppl: 225.340377224\n",
            "valid_ppl: 356.266744414\n",
            "test_ppl: 288.184551098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8ranM0ERNIta",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Size of the hidden layer"
      ]
    },
    {
      "metadata": {
        "id": "vbkbvBaWLVaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "84dc1cfe-578c-4200-82f6-e8d81afed187"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='LSTM', optimizer='Adam', lr=0.01, hidden_size=64)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 522.602473469\n",
            "valid_ppl: 433.018669464\n",
            "Epoch 2\n",
            "train_ppl: 325.534562413\n",
            "valid_ppl: 382.469223656\n",
            "Epoch 3\n",
            "train_ppl: 271.586685795\n",
            "valid_ppl: 365.897337815\n",
            "Epoch 4\n",
            "train_ppl: 241.188401725\n",
            "valid_ppl: 356.627466171\n",
            "Epoch 5\n",
            "train_ppl: 221.587265914\n",
            "valid_ppl: 352.766427407\n",
            "test_ppl: 279.318501236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F8O4aKe2NDBB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Regularization"
      ]
    },
    {
      "metadata": {
        "id": "YFKOAC30M1AA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1fdacc68-ef0f-4818-af8b-50ee50046552"
      },
      "cell_type": "code",
      "source": [
        "run_lm(cell='LSTM', optimizer='Adam', lr=0.01, dropout_rate=0.1)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 809.953863498\n",
            "valid_ppl: 658.909363669\n",
            "Epoch 2\n",
            "train_ppl: 584.828653476\n",
            "valid_ppl: 606.689601129\n",
            "Epoch 3\n",
            "train_ppl: 539.409788271\n",
            "valid_ppl: 585.649933925\n",
            "Epoch 4\n",
            "train_ppl: 519.498692319\n",
            "valid_ppl: 574.898769121\n",
            "Epoch 5\n",
            "train_ppl: 508.607510944\n",
            "valid_ppl: 574.182146616\n",
            "test_ppl: 517.1558548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UozYDTgTPYBN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing a network"
      ]
    },
    {
      "metadata": {
        "id": "J1EsT6GWPao5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "bQ1ZQsmOBoFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "089e0084-1530-4f1f-c9f4-69cdaae6b647"
      },
      "cell_type": "code",
      "source": [
        "emb_matrix = run_lm(cell='LSTM', optimizer='Adam', lr=0.01, inspect_emb=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 483.931723677\n",
            "valid_ppl: 390.636586065\n",
            "Epoch 2\n",
            "train_ppl: 285.191311326\n",
            "valid_ppl: 347.937371977\n",
            "Epoch 3\n",
            "train_ppl: 234.46256545\n",
            "valid_ppl: 338.683691805\n",
            "Epoch 4\n",
            "train_ppl: 206.617723388\n",
            "valid_ppl: 336.448053915\n",
            "Epoch 5\n",
            "train_ppl: 188.752548267\n",
            "valid_ppl: 336.157748167\n",
            "('Saved the model to ', 'models/rnn.ckpt')\n",
            "test_ppl: 256.59022607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4uiZ1zheg2FJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9534a2-6c1c-4107-d088-bb9d0691f420"
      },
      "cell_type": "code",
      "source": [
        "print(emb_matrix)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Model/embedding:0\", shape=(10001, 64), dtype=float32_ref)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}