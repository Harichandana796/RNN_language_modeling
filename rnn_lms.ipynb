{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_lms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/lverwimp/RNN_language_modeling/blob/master/rnn_lms.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "esuUK2ev_Nyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ]
    },
    {
      "metadata": {
        "id": "_yKJ-Plo_HTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import urllib, collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BddwEvSP_ekG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Enable eager execution in TensorFlow:"
      ]
    },
    {
      "metadata": {
        "id": "CQPkGtgt_huR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oKtBwJQAJED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get training, validation and test data:"
      ]
    },
    {
      "metadata": {
        "id": "t6AIeiR2BaMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/train.txt'\n",
        "valid_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/valid.txt'\n",
        "test_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/test.txt'\n",
        "train_file = urllib.urlopen(train_url).read()\n",
        "valid_file = urllib.urlopen(valid_url).read()\n",
        "test_file = urllib.urlopen(test_url).read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Ye3oJavH-8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The data looks like this:"
      ]
    },
    {
      "metadata": {
        "id": "GXEcoaWKIAtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "52e0a6db-cce6-485b-f02b-8a6d5006846b"
      },
      "cell_type": "code",
      "source": [
        "print('{0}...'.format(valid_file[:500]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " consumers may want to move their telephones a little closer to the tv set \n",
            " <unk> <unk> watching abc 's monday night football can now vote during <unk> for the greatest play in N years from among four or five <unk> <unk> \n",
            " two weeks ago viewers of several nbc <unk> consumer segments started calling a N number for advice on various <unk> issues \n",
            " and the new syndicated reality show hard copy records viewers ' opinions for possible airing on the next day 's show \n",
            " interactive telephone technology...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ZF1PoUJDRkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<unk\\> is a symbol for the unknown words class, 'N' is a symbol used for the numbers class.\n",
        "  \n",
        "Convert data to correct format:"
      ]
    },
    {
      "metadata": {
        "id": "Y531EV5aDVd0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the string to a list and replace newlines with the end-of-sentence symbol\n",
        "train_text = [w for w in train_file.replace('\\n',' <eos>').split(' ')]\n",
        "valid_text = [w for w in valid_file.replace('\\n',' <eos>').split(' ')]\n",
        "test_text = [w for w in test_file.replace('\\n',' <eos>').split(' ')]\n",
        "\n",
        "# count the frequencies of the words in the training data\n",
        "counter = collections.Counter(train_text)\n",
        "\n",
        "# sort according to decreasing frequency\n",
        "count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "# words = list of all the words (in decreasing frequency)\n",
        "items, _ = list(zip(*count_pairs))\n",
        "\n",
        "# make a dictionary with a mapping from each word to an id; word with highest frequency gets lowest id etc.\n",
        "item_to_id = dict(zip(items, range(len(items))))\n",
        "\n",
        "# convert the words to indices\n",
        "train_ids = [item_to_id[item] for item in train_text]\n",
        "valid_ids = [item_to_id[item] for item in valid_text]\n",
        "test_ids = [item_to_id[item] for item in test_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6KQShlZFcGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once the data is converted to ids, it looks like this:"
      ]
    },
    {
      "metadata": {
        "id": "Vlo5SpAHFhLq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b86cd6d1-2bdd-4237-efeb-7e0b7c1e925c"
      },
      "cell_type": "code",
      "source": [
        "print(valid_ids[:100])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 1133, 94, 359, 6, 330, 52, 9837, 7, 327, 2477, 6, 0, 663, 389, 2, 3, 1, 1, 2975, 2159, 10, 382, 1069, 2348, 90, 100, 848, 199, 1, 12, 0, 3384, 1120, 8, 4, 73, 21, 212, 347, 37, 259, 1, 1, 2, 3, 76, 423, 196, 3918, 5, 250, 1796, 1, 581, 3529, 893, 2375, 7, 4, 298, 12, 2710, 17, 1187, 1, 251, 2, 3, 9, 0, 36, 9923, 3748, 465, 711, 2999, 2038, 3918, 135, 6146, 12, 495, 5895, 17, 0, 131, 273, 10, 465, 2, 3, 9959, 733, 504, 31, 642, 7, 36, 6499]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jBnJVfPuNzmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Class for the language model:"
      ]
    },
    {
      "metadata": {
        "id": "e_IlLSYXN1h7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class rnn_lm(object):\n",
        "  '''\n",
        "  This is a class to build and execute a recurrent neural network language model.\n",
        "  '''\n",
        "  \n",
        "  def __init__(self,\n",
        "              cell='LSTM',\n",
        "              vocab_size=10000,\n",
        "              embedding_size=64,\n",
        "              hidden_size=128,\n",
        "              dropout_rate=0.5):\n",
        "    self.cell = cell\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dropout_rate = dropout_rate\n",
        "    \n",
        "  def build_training_graph(self):\n",
        "    \n",
        "    self.embedding = tf.get_variable(\"embedding\", [self.vocab_size, self.embedding_size], dtype=tf.float32)\n",
        "    \n",
        "    self.cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size, forget_bias=self.config['forget_bias'],\n",
        "\t\t\t\t\tstate_is_tuple=True, reuse=self.reuse) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}