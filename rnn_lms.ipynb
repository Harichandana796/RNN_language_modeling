{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_lms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/lverwimp/RNN_language_modeling/blob/master/rnn_lms.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "esuUK2ev_Nyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ]
    },
    {
      "metadata": {
        "id": "_yKJ-Plo_HTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib, collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UScGV-tTaZba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some global variables:"
      ]
    },
    {
      "metadata": {
        "id": "KNbwMREbacvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 20\n",
        "NUM_STEPS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oKtBwJQAJED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get training, validation and test data:"
      ]
    },
    {
      "metadata": {
        "id": "t6AIeiR2BaMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/train.txt'\n",
        "valid_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/valid.txt'\n",
        "test_url = 'http://homes.esat.kuleuven.be/~lverwimp/course_speech_recognition/test.txt'\n",
        "train_file = urllib.urlopen(train_url).read()\n",
        "valid_file = urllib.urlopen(valid_url).read()\n",
        "test_file = urllib.urlopen(test_url).read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Ye3oJavH-8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The data looks like this:"
      ]
    },
    {
      "metadata": {
        "id": "GXEcoaWKIAtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "25354e27-c157-41db-9603-80d8e2740491"
      },
      "cell_type": "code",
      "source": [
        "print('{0}...'.format(valid_file[:500]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " consumers may want to move their telephones a little closer to the tv set \n",
            " <unk> <unk> watching abc 's monday night football can now vote during <unk> for the greatest play in N years from among four or five <unk> <unk> \n",
            " two weeks ago viewers of several nbc <unk> consumer segments started calling a N number for advice on various <unk> issues \n",
            " and the new syndicated reality show hard copy records viewers ' opinions for possible airing on the next day 's show \n",
            " interactive telephone technology...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ZF1PoUJDRkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<unk\\> is a symbol for the unknown words class, 'N' is a symbol used for the numbers class.\n",
        "  \n",
        "Convert data to correct format:"
      ]
    },
    {
      "metadata": {
        "id": "Y531EV5aDVd0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the string to a list and replace newlines with the end-of-sentence symbol\n",
        "train_text = [w for w in train_file.replace('\\n',' <eos>').split(' ')]\n",
        "valid_text = [w for w in valid_file.replace('\\n',' <eos>').split(' ')]\n",
        "test_text = [w for w in test_file.replace('\\n',' <eos>').split(' ')]\n",
        "\n",
        "# count the frequencies of the words in the training data\n",
        "counter = collections.Counter(train_text)\n",
        "\n",
        "# sort according to decreasing frequency\n",
        "count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "# words = list of all the words (in decreasing frequency)\n",
        "items, _ = list(zip(*count_pairs))\n",
        "\n",
        "# make a dictionary with a mapping from each word to an id; word with highest frequency gets lowest id etc.\n",
        "item_to_id = dict(zip(items, range(len(items))))\n",
        "id_to_item = dict(zip(range(len(items)), items))\n",
        "vocab_size = len(item_to_id)\n",
        "\n",
        "# convert the words to indices\n",
        "train_ids_large = [item_to_id[item] for item in train_text]\n",
        "valid_ids_large = [item_to_id[item] for item in valid_text]\n",
        "test_ids_large = [item_to_id[item] for item in test_text]\n",
        "\n",
        "# take a smaller subset to speed up training\n",
        "train_ids = train_ids_large[:200000]\n",
        "valid_ids = valid_ids_large[:20000]\n",
        "test_ids = test_ids_large[:20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6KQShlZFcGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once the data is converted to ids, it looks like this:"
      ]
    },
    {
      "metadata": {
        "id": "Vlo5SpAHFhLq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e23be379-d350-4dd0-ac93-f11a88a1805d"
      },
      "cell_type": "code",
      "source": [
        "print(valid_ids[:100])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 1133, 94, 359, 6, 330, 52, 9837, 7, 327, 2477, 6, 0, 663, 389, 2, 3, 1, 1, 2975, 2159, 10, 382, 1069, 2348, 90, 100, 848, 199, 1, 12, 0, 3384, 1120, 8, 4, 73, 21, 212, 347, 37, 259, 1, 1, 2, 3, 76, 423, 196, 3918, 5, 250, 1796, 1, 581, 3529, 893, 2375, 7, 4, 298, 12, 2710, 17, 1187, 1, 251, 2, 3, 9, 0, 36, 9923, 3748, 465, 711, 2999, 2038, 3918, 135, 6146, 12, 495, 5895, 17, 0, 131, 273, 10, 465, 2, 3, 9959, 733, 504, 31, 642, 7, 36, 6499]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jBnJVfPuNzmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Class for the language model:"
      ]
    },
    {
      "metadata": {
        "id": "e_IlLSYXN1h7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class rnn_lm(object):\n",
        "  '''\n",
        "  This is a class to build and execute a recurrent neural network language model.\n",
        "  '''\n",
        "  \n",
        "  def __init__(self,\n",
        "              cell='LSTM',\n",
        "              vocab_size=10000,\n",
        "              embedding_size=64,\n",
        "              hidden_size=128,\n",
        "              dropout_rate=0.5,\n",
        "              is_training=True):\n",
        "    self.which_cell = cell\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.is_training = is_training\n",
        "    self.batch_size = BATCH_SIZE\n",
        "    self.num_steps = NUM_STEPS\n",
        "    self.max_grad_norm = 5\n",
        "    self.lr = 1\n",
        "    \n",
        "    self.init_graph()\n",
        "    \n",
        "    self.output, self.state = self.feed_to_network()\n",
        "    \n",
        "    self.loss = self.calc_loss(self.output)\n",
        "    \n",
        "    if self.is_training:\n",
        "      self.update_params(self.loss)\n",
        "    \n",
        "    \n",
        "  def init_graph(self):\n",
        "    '''\n",
        "    This function initializes all elements of the network.\n",
        "    '''\n",
        "    \n",
        "    self.inputs = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, self.num_steps])\n",
        "    self.targets = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, self.num_steps])\n",
        "    \n",
        "    # input embedding weights\n",
        "    self.embedding = tf.get_variable(\"embedding\", \n",
        "                                     [self.vocab_size, self.embedding_size], \n",
        "                                     dtype=tf.float32)\n",
        "    \n",
        "    # hidden layer\n",
        "    if self.which_cell == 'LSTM':\n",
        "      self.basic_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size)\n",
        "    elif self.which_cell == 'RNN':\n",
        "      self.basic_cell = tf.contrib.rnn.BasicRNNCell(self.hidden_size)\n",
        "    elif self.which_cell == 'GRU':\n",
        "      self.basic_cell = tf.contrib.rnn.GRUCell(self.hidden_size)\n",
        "    else:\n",
        "      raise IOError(\"Specify which type of RNN you want to use: RNN, GRU or LSTM.\")\n",
        "      \n",
        "    # apply dropout  \n",
        "    self.cell = tf.contrib.rnn.DropoutWrapper(self.basic_cell, \n",
        "                                              output_keep_prob=self.dropout_rate)\n",
        "    \n",
        "    # initial state contains all zeros\n",
        "    self.initial_state = self.cell.zero_state(self.batch_size, tf.float32)\n",
        "    \n",
        "    # output weight matrix and bias\n",
        "    self.softmax_w = tf.get_variable(\"softmax_w\",\n",
        "                                     [self.hidden_size, self.vocab_size], \n",
        "                                     dtype=tf.float32)\n",
        "    self.softmax_b = tf.get_variable(\"softmax_b\",\n",
        "                                     [self.vocab_size], \n",
        "                                     dtype=tf.float32)\n",
        "    \n",
        "    self.initial_state = self.cell.zero_state(self.batch_size, dtype=tf.float32)\n",
        "    \n",
        "    \n",
        "  def feed_to_network(self):\n",
        "    '''\n",
        "    This function feeds the input to the network and returns the output and the state.\n",
        "   \n",
        "    '''\n",
        "    \n",
        "    # map input indices to continuous input vectors\n",
        "    inputs = tf.nn.embedding_lookup(self.embedding, self.inputs)\n",
        "\n",
        "\t  # use dropout on the input embeddings\n",
        "    inputs = tf.nn.dropout(inputs, self.dropout_rate)\n",
        "    \n",
        "    state = self.initial_state\n",
        "    \n",
        "    # feed inputs to network: outputs = predictions, state = new hidden state\n",
        "    outputs, state = tf.nn.dynamic_rnn(self.cell, inputs, sequence_length=None, initial_state=state)\n",
        "    \n",
        "    output = tf.reshape(tf.concat(outputs, 1), [-1, self.hidden_size])\n",
        "    \n",
        "    return output, state\n",
        "    \n",
        "  \n",
        "  def calc_loss(self, output):\n",
        "    \n",
        "    # calculate logits\n",
        "    logits = tf.matmul(output, self.softmax_w) + self.softmax_b\n",
        "      \n",
        "    # calculate cross entropy loss\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=tf.reshape(self.targets, [-1]), logits=logits)\n",
        "      \n",
        "    # average loss per batch\n",
        "    avg_loss = tf.reduce_sum(loss) / self.batch_size\n",
        "    \n",
        "    return avg_loss\n",
        "  \n",
        "  def update_params(self, loss):\n",
        "    \n",
        "    # calculate gradients for all trainable variables \n",
        "    # + clip them if their global norm > 5 (prevents exploding gradients)\n",
        "    grads, _ = tf.clip_by_global_norm(\n",
        "        tf.gradients(loss, tf.trainable_variables()), self.max_grad_norm)\n",
        "    \n",
        "    # optimize with stochastic gradient descent\n",
        "    optimizer = tf.train.GradientDescentOptimizer(self.lr)\n",
        "    \n",
        "    # update the weights\n",
        "    self.train_op = optimizer.apply_gradients(\n",
        "\t\t\t\tzip(grads, tf.trainable_variables()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIHeGqTCW8J-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a class that will generate mini-batches from the data."
      ]
    },
    {
      "metadata": {
        "id": "sEvlMOEJa4qU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class batchGenerator(object):\n",
        "  '''\n",
        "  This class generates batches for a dataset.\n",
        "  Input argument:\n",
        "    data: list of indices (word ids)\n",
        "  '''\n",
        "  \n",
        "  def __init__(self, data):\n",
        "    '''\n",
        "    Prepares a dataset.\n",
        "    '''\n",
        "  \n",
        "    data_array = np.array(data)\n",
        "\n",
        "    len_batch_instance = len(data) / BATCH_SIZE\n",
        "\n",
        "    data_array = data_array[:BATCH_SIZE*len_batch_instance]\n",
        "\n",
        "    # divide data in BATCH_SIZE parts\n",
        "    self.data_reshaped = np.reshape(data_array, (BATCH_SIZE, len_batch_instance))\n",
        "\n",
        "    # number of mini-batches that can be generated\n",
        "    self.num_batches_in_data = len_batch_instance / NUM_STEPS - 1\n",
        "    \n",
        "    self.curr_idx = 0\n",
        "  \n",
        "  def generate(self):\n",
        "    '''\n",
        "    Generates\n",
        "      input_batch: numpy array or None, if the end of the dataset is reached\n",
        "      target_batch: numpy array or None, if the end of the dataset is reached\n",
        "      end_reached: boolean, True is end of dataset is reached\n",
        "    '''\n",
        "    \n",
        "    if self.curr_idx >= self.num_batches_in_data:\n",
        "      return None, None, True\n",
        "\n",
        "    # input: take slice of size BATCH_\n",
        "    input_batch = self.data_reshaped[:,self.curr_idx*BATCH_SIZE:self.curr_idx*BATCH_SIZE+BATCH_SIZE]\n",
        "    \n",
        "    # target = input shifted 1 time step\n",
        "    target_batch = self.data_reshaped[:,self.curr_idx*BATCH_SIZE+1:self.curr_idx*BATCH_SIZE+BATCH_SIZE+1]    \n",
        "\n",
        "    self.curr_idx += 1\n",
        "    \n",
        "    return input_batch, target_batch, False\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_SB0UTRdnU5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is an example of how batchGenerator can be used. You will notice that the target batch contains the same indices as the input batch, but shifted one (time) step to the right."
      ]
    },
    {
      "metadata": {
        "id": "qHiY_eJ0dpUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        },
        "outputId": "a8c81111-42c2-4e71-d464-a6a1a89ae492"
      },
      "cell_type": "code",
      "source": [
        "generator = batchGenerator(valid_ids)\n",
        "input_batch, target_batch, end_reached = generator.generate()\n",
        "print('This is what an input batch looks like:\\n{0}'.format(input_batch))\n",
        "print('And this is what a target batch looks like:\\n{0}'.format(target_batch))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is what an input batch looks like:\n",
            "[[   2 1133   94  359    6  330   52 9837    7  327 2477    6    0  663\n",
            "   389    2    3    1    1 2975]\n",
            " [  30   15   10 1540    6   26   44    4    4  626 2039    1  173    2\n",
            "     3   65   47  584    6  189]\n",
            " [   1   95 2469   11  390    1   47  214 9936   20    1   80   26 1950\n",
            "    67    0    1    5    1  175]\n",
            " [ 146 2370   16    2    3  640  748 3382 4740 2785   57  336  562    8\n",
            "  1120   23    7   13    4   49]\n",
            " [  47 3280   11   24 2785   37   55    5    0   62 1379 1557  280    1\n",
            "    23    0  948    8 6393   37]\n",
            " [  15  176   33 1056    6  330  122 1296   28    1 1853    8  133 8666\n",
            "  9744    2    3   68   24 2670]\n",
            " [1094  485    1 3218   94   26  659    6  621   11 1030   30 1371   37\n",
            "  6552 8336  128   20   39    1]\n",
            " [   2    3   36  632 4168   83 3089   96 3254 2369    0  695  904   12\n",
            "    28  463    5 1768    1    1]\n",
            " [ 607  363    2    3    1 2848   10    1 3404  193    7 5443    2    3\n",
            "   190    1   35    6   26   75]\n",
            " [   6  300   30    0 2035 1205   17    0  911 7360  160  128 1155   15\n",
            "     2    3  111  379 2932   51]\n",
            " [3059   70   41   68  229    1   47  214 6300    2    3 1090  167   11\n",
            "   846 9920   53 2932   10 7448]\n",
            " [1558 6121   37 5187 7705   35 1899  361    9    0   36  839   27 8690\n",
            "   946   57  160  162    8    0]\n",
            " [ 442   23 9976    2    3   12 1224   29  595    7   13    4   22  502\n",
            "    21    0 3414 3397   19    7]\n",
            " [1390 9896    9  681    0  599 2272  680   19    0 1860    2    3   17\n",
            "  9758   29  490    7  242  116]\n",
            " [ 288  489   31    4   22  247   72  547    2    3    1  720   51   16\n",
            "    15  955    6 3751   72   30]\n",
            " [5319   48    2    3    0   61   48 8597   33  325    6   88  122    5\n",
            "   997   12    7  121   45  401]\n",
            " [ 242  208   37  891  137   80  379   52   72  461  290   46   56    4\n",
            "     4    2    3    0 2763   17]\n",
            " [   8  271   21 2165    1  645    2    3    0  213    8    7    4 1230\n",
            "  5857   85    7 3167  389   18]\n",
            " [   9  289  474    2    3   24    1   25  233   71    9  277  353  572\n",
            "     5    1 3050    1   81    7]\n",
            " [1836 6986    4   73  394   71    9  152  155  291    5 5411  931    5\n",
            "   541   81   25 1235    7  277]]\n",
            "And this is what a target batch looks like:\n",
            "[[1133   94  359    6  330   52 9837    7  327 2477    6    0  663  389\n",
            "     2    3    1    1 2975 2159]\n",
            " [  15   10 1540    6   26   44    4    4  626 2039    1  173    2    3\n",
            "    65   47  584    6  189 1699]\n",
            " [  95 2469   11  390    1   47  214 9936   20    1   80   26 1950   67\n",
            "     0    1    5    1  175    1]\n",
            " [2370   16    2    3  640  748 3382 4740 2785   57  336  562    8 1120\n",
            "    23    7   13    4   49  258]\n",
            " [3280   11   24 2785   37   55    5    0   62 1379 1557  280    1   23\n",
            "     0  948    8 6393   37   11]\n",
            " [ 176   33 1056    6  330  122 1296   28    1 1853    8  133 8666 9744\n",
            "     2    3   68   24 2670 5987]\n",
            " [ 485    1 3218   94   26  659    6  621   11 1030   30 1371   37 6552\n",
            "  8336  128   20   39    1    8]\n",
            " [   3   36  632 4168   83 3089   96 3254 2369    0  695  904   12   28\n",
            "   463    5 1768    1    1    1]\n",
            " [ 363    2    3    1 2848   10    1 3404  193    7 5443    2    3  190\n",
            "     1   35    6   26   75    6]\n",
            " [ 300   30    0 2035 1205   17    0  911 7360  160  128 1155   15    2\n",
            "     3  111  379 2932   51   40]\n",
            " [  70   41   68  229    1   47  214 6300    2    3 1090  167   11  846\n",
            "  9920   53 2932   10 7448    2]\n",
            " [6121   37 5187 7705   35 1899  361    9    0   36  839   27 8690  946\n",
            "    57  160  162    8    0   61]\n",
            " [  23 9976    2    3   12 1224   29  595    7   13    4   22  502   21\n",
            "     0 3414 3397   19    7    1]\n",
            " [9896    9  681    0  599 2272  680   19    0 1860    2    3   17 9758\n",
            "    29  490    7  242  116   24]\n",
            " [ 489   31    4   22  247   72  547    2    3    1  720   51   16   15\n",
            "   955    6 3751   72   30  144]\n",
            " [  48    2    3    0   61   48 8597   33  325    6   88  122    5  997\n",
            "    12    7  121   45  401    1]\n",
            " [ 208   37  891  137   80  379   52   72  461  290   46   56    4    4\n",
            "     2    3    0 2763   17  331]\n",
            " [ 271   21 2165    1  645    2    3    0  213    8    7    4 1230 5857\n",
            "    85    7 3167  389   18    0]\n",
            " [ 289  474    2    3   24    1   25  233   71    9  277  353  572    5\n",
            "     1 3050    1   81    7 2113]\n",
            " [6986    4   73  394   71    9  152  155  291    5 5411  931    5  541\n",
            "    81   25 1235    7  277    5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vBbmu8MyeRjg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a function that does one pass over the whole dataset. If we are training the model, it will update the parameters and return the perplexity. Otherwise, it will just return the perplexity."
      ]
    },
    {
      "metadata": {
        "id": "u0QxAecTZIOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_epoch(session, rnn, data, is_training=True):\n",
        "    '''\n",
        "    This function runs a single epoch (pass) over the data,\n",
        "    updating the model parameters if we are training,\n",
        "    and returns the perplexity.\n",
        "    Input arguments:\n",
        "      rnn: object of the rnn_lm class\n",
        "      data: list of word indices\n",
        "      is_training: boolean, True is we are training the model\n",
        "    Returns:\n",
        "      ppl: float, perplexity of the dataset\n",
        "    '''\n",
        "  \n",
        "    generator = batchGenerator(data)\n",
        "      \n",
        "    state = session.run(rnn.initial_state)\n",
        "    sum_loss = 0.0\n",
        "    iters = 0\n",
        "      \n",
        "    while True:\n",
        "\n",
        "      input_batch, target_batch, end_reached = generator.generate()\n",
        "        \n",
        "      if end_reached:\n",
        "        break\n",
        "\n",
        "      feed_dict = {rnn.inputs: input_batch,\n",
        "                  rnn.targets: target_batch,\n",
        "                  rnn.initial_state : state}\n",
        "\n",
        "      fetches = {'loss': rnn.loss,\n",
        "                'state': rnn.state}\n",
        "      \n",
        "      if is_training:\n",
        "        fetches['train_op'] = rnn.train_op\n",
        "\n",
        "      result = session.run(fetches, feed_dict)\n",
        "        \n",
        "      state = result['state']\n",
        "      loss = result['loss']\n",
        "\n",
        "      sum_loss += loss\n",
        "      iters += NUM_STEPS\n",
        "        \n",
        "    ppl = np.exp(sum_loss / iters)\n",
        "    \n",
        "    return ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CY4KxCsUenOy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This function can be called to build, train and test models with different parameter settings. "
      ]
    },
    {
      "metadata": {
        "id": "5K8dJkswaT7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_lm():\n",
        "  '''\n",
        "  Creates training, validation and/or test models,\n",
        "  trains, validates and/or tests the model.\n",
        "  '''\n",
        "  \n",
        "  with tf.Graph().as_default():\n",
        "\n",
        "      with tf.variable_scope(\"Model\"):\n",
        "        rnn_train = rnn_lm(vocab_size=vocab_size)\n",
        "      with tf.variable_scope(\"Model\", reuse=True):\n",
        "        rnn_valid = rnn_lm(vocab_size=vocab_size, is_training=False)\n",
        "      with tf.variable_scope(\"Model\", reuse=True):\n",
        "        rnn_test = rnn_lm(vocab_size=vocab_size, is_training=False)\n",
        "      \n",
        "\n",
        "      sv = tf.train.Supervisor()\n",
        "\n",
        "      with sv.managed_session(config=tf.ConfigProto()) as session:\n",
        "        \n",
        "        for i in xrange(5):\n",
        "          \n",
        "          print('Epoch {0}'.format(i+1))\n",
        "\n",
        "          train_ppl = run_epoch(session, rnn_train, train_ids)\n",
        "          print('train_ppl: {0}'.format(train_ppl))\n",
        "\n",
        "          valid_ppl = run_epoch(session, rnn_valid, valid_ids, is_training=False)\n",
        "          print('valid_ppl: {0}'.format(valid_ppl))\n",
        "\n",
        "        test_ppl = run_epoch(session, rnn_test, test_ids, is_training=False)\n",
        "        print('test_ppl: {0}'.format(test_ppl))\n",
        "        \n",
        "        \n",
        "      \n",
        "      \n",
        "        \n",
        "     \n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRUa0rDYc7SC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "565393d4-95c7-4361-be95-16c646c2f91c"
      },
      "cell_type": "code",
      "source": [
        "run_lm()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting standard services.\n",
            "WARNING:tensorflow:Standard services need a 'logdir' passed to the SessionManager\n",
            "INFO:tensorflow:Starting queue runners.\n",
            "Epoch 1\n",
            "train_ppl: 486.357779209\n",
            "valid_ppl: 339.133497603\n",
            "Epoch 2\n",
            "train_ppl: 268.892308079\n",
            "valid_ppl: 298.921601973\n",
            "Epoch 3\n",
            "train_ppl: 220.752845014\n",
            "valid_ppl: 279.741526476\n",
            "Epoch 4\n",
            "train_ppl: 196.242662901\n",
            "valid_ppl: 275.163753012\n",
            "Epoch 5\n",
            "train_ppl: 181.286802735\n",
            "valid_ppl: 272.032202024\n",
            "test_ppl: 219.384786118\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}